{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1000Genomes_updated_A1 (1) (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeSD26oF7plX"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpPTTdAs8Ie_"
      },
      "source": [
        "#Read vcf file from the 1000 genomes project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBWzbKwcbcDE"
      },
      "source": [
        "## The reading and of the data from the 1000s genome's project was adopted from @LucilleWerner project on github as this was very helpful\n",
        "import gzip\n",
        "import pandas\n",
        "import cudf\n",
        "import cupy as cp\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "vcf_file = \"1000G_chr1_1-1000001.vcf\"\n",
        "vcf = open(vcf_file, 'r')\n",
        "\n",
        "# if the VCF is big, we van prevent flooding the memory by reading the file line by line\n",
        "go = True\n",
        "while go:\n",
        "    line = vcf.readline()\n",
        "#     line = line.decode('utf-8')\n",
        "    # this line contains the headers and also all the sample names\n",
        "    if line.startswith('#C'):\n",
        "        split_line = line.split('\\t')\n",
        "\n",
        "        samples = split_line[9:]\n",
        "        samples[-1] = samples[-1].strip('\\n')\n",
        "        break\n",
        "\n",
        "# sort samples on their ID\n",
        "samples = sorted(samples)\n",
        "\n",
        "# indexing the data frame on the sample names using pandas, this is convenient for merging later on\n",
        "samples_idx = pandas.DataFrame(index=samples)\n",
        "\n",
        "\n",
        "#indexing the data frame on the sample names using cuda's cudf\n",
        "samples_idx1 = cudf.DataFrame(index=samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjtNx93Sut4p",
        "outputId": "ee0b83eb-0efa-4919-c58a-cd2fa1024b7d"
      },
      "source": [
        "#Find the distribution of the data to have a rough understanding of what features can be removed\n",
        "samples.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rs367896724</th>\n",
              "      <th>rs540431307</th>\n",
              "      <th>rs555500075</th>\n",
              "      <th>rs548419688</th>\n",
              "      <th>rs568405545</th>\n",
              "      <th>rs534229142</th>\n",
              "      <th>rs537182016</th>\n",
              "      <th>rs572818783</th>\n",
              "      <th>rs538322974</th>\n",
              "      <th>rs376342519</th>\n",
              "      <th>...</th>\n",
              "      <th>rs565260701</th>\n",
              "      <th>rs115261610</th>\n",
              "      <th>rs371001401</th>\n",
              "      <th>rs184916420</th>\n",
              "      <th>rs150732520</th>\n",
              "      <th>rs546906682</th>\n",
              "      <th>rs139091112</th>\n",
              "      <th>rs538925052</th>\n",
              "      <th>rs112150631</th>\n",
              "      <th>rs189331984</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>...</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "      <td>2535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0|1</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|1</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>1|1</td>\n",
              "      <td>...</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "      <td>0|0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1505</td>\n",
              "      <td>2529</td>\n",
              "      <td>2049</td>\n",
              "      <td>2534</td>\n",
              "      <td>2534</td>\n",
              "      <td>2534</td>\n",
              "      <td>2532</td>\n",
              "      <td>2534</td>\n",
              "      <td>2534</td>\n",
              "      <td>2499</td>\n",
              "      <td>...</td>\n",
              "      <td>2533</td>\n",
              "      <td>2513</td>\n",
              "      <td>2526</td>\n",
              "      <td>2529</td>\n",
              "      <td>2509</td>\n",
              "      <td>2533</td>\n",
              "      <td>2497</td>\n",
              "      <td>2533</td>\n",
              "      <td>2344</td>\n",
              "      <td>2509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 13436 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       rs367896724 rs540431307 rs555500075 rs548419688 rs568405545  \\\n",
              "count         2535        2535        2535        2535        2535   \n",
              "unique           3           2           3           2           2   \n",
              "top            0|1         0|0         0|1         0|0         0|0   \n",
              "freq          1505        2529        2049        2534        2534   \n",
              "\n",
              "       rs534229142 rs537182016 rs572818783 rs538322974 rs376342519  ...  \\\n",
              "count         2535        2535        2535        2535        2535  ...   \n",
              "unique           2           2           2           2           2  ...   \n",
              "top            0|0         0|0         0|0         0|0         1|1  ...   \n",
              "freq          2534        2532        2534        2534        2499  ...   \n",
              "\n",
              "       rs565260701 rs115261610 rs371001401 rs184916420 rs150732520  \\\n",
              "count         2535        2535        2535        2535        2535   \n",
              "unique           2           2           2           2           2   \n",
              "top            0|0         0|0         0|0         0|0         0|0   \n",
              "freq          2533        2513        2526        2529        2509   \n",
              "\n",
              "       rs546906682 rs139091112 rs538925052 rs112150631 rs189331984  \n",
              "count         2535        2535        2535        2535        2535  \n",
              "unique           2           2           2           3           2  \n",
              "top            0|0         0|0         0|0         0|0         0|0  \n",
              "freq          2533        2497        2533        2344        2509  \n",
              "\n",
              "[4 rows x 13436 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgqcwUiabcDF",
        "outputId": "5d51121d-abde-4736-a37f-9b53a8fa5916"
      },
      "source": [
        "#load file containing top 100 snp predictive features\n",
        "####  Here is a list of Ancestry Indicative Markers from literature that was selected to aid in the analysis\n",
        "%time df = pd.read_csv('SNP_select.csv')\n",
        "df.columns = ['snpID']\n",
        "df.shape\n",
        "\n",
        "df1 = df.values.tolist()\n",
        "df2 = str(df1)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 1.97 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"[['rs2297679 '], ['rs7013027 '], ['rs733290 '], ['rs1844396'], ['rs1356733 '], ['rs152280'], [' rs2324909 '], ['rs4751629 '], ['rs1281340'], ['rs11164559 '], ['rs3128917 '], ['rs10188217 '], ['rs10872465 '], ['rs1467044 '], ['rs2172159 '], ['rs6583859 '], ['rs9960403 '], ['rs2441727 '], ['rs12777190 '], ['rs4706511 '], ['rs12759306 '], ['rs11097457 '], ['rs12594390 '], ['rs7646054 '], ['rs6012906 '], ['rs6050374 '], ['rs4785919'], [' rs156984 '], ['rs3943733 '], ['rs1512744 '], ['rs641902'], ['rs3816969'], [' rs6496173 '], ['rs4921809 '], ['rs250850'], ['rs4242165 '], ['rs1463652 '], ['rs12670839 '], ['rs2589655'], ['rs2303942 '], ['rs10505909 '], ['rs441517 '], ['rs7358335'], ['rs2427622 '], ['rs10746709 '], ['rs2276070 '], ['rs6681880'], ['rs2424303 '], ['rs3873386 '], ['rs4870268 '], ['rs867926'], ['rs7656234 '], ['rs3105439 '], ['rs2417680 '], ['rs4577244'], ['rs746124 '], ['rs9314379 '], ['rs10519410 '], ['rs11096674'], ['rs6741951 '], ['rs10497705 '], ['rs39108 '], ['rs4973190'], ['rs10510633 '], ['rs3006198 '], ['rs6958889 '], ['rs4269797'], ['rs10189760 '], ['rs16913731 '], ['rs7732983 '], ['rs181247'], ['rs4800827 '], ['rs10850434 '], ['rs10515467 '], ['rs11195943'], ['rs1391451 '], ['rs11811536 '], ['rs12576387 '], ['rs7660783'], ['rs10493856 '], ['rs17494100 '], ['rs7404238 '], ['rs1322755'], ['rs2256965 '], ['rs1801249 '], ['rs149332 '], ['rs7580688'], ['rs4280690 '], ['rs4648527 '], ['rs12347149 '], ['rs1906990'], ['rs2102272 '], ['rs9812253 '], ['rs4741546 '], ['rs2918285'], ['rs975664'], ['rs2822987'], ['rs10134505'], ['rs7539636']]\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lpDRUR4bcDH",
        "scrolled": true,
        "outputId": "e375688d-e1a2-44a8-ca82-c7eda593f665"
      },
      "source": [
        "%time samples_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 5.96 µs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HG00096</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00097</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00099</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00101</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21137</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21141</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21142</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21143</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21144</th>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2535 rows × 0 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: [HG00096, HG00097, HG00099, HG00100, HG00101, HG00102, HG00103, HG00105, HG00106, HG00107, HG00108, HG00109, HG00110, HG00111, HG00112, HG00113, HG00114, HG00115, HG00116, HG00117, HG00118, HG00119, HG00120, HG00121, HG00122, HG00123, HG00124, HG00125, HG00126, HG00127, HG00128, HG00129, HG00130, HG00131, HG00132, HG00133, HG00136, HG00137, HG00138, HG00139, HG00140, HG00141, HG00142, HG00143, HG00145, HG00146, HG00148, HG00149, HG00150, HG00151, HG00154, HG00155, HG00157, HG00158, HG00159, HG00160, HG00171, HG00173, HG00174, HG00176, HG00177, HG00178, HG00179, HG00180, HG00181, HG00182, HG00183, HG00185, HG00186, HG00187, HG00188, HG00189, HG00190, HG00231, HG00232, HG00233, HG00234, HG00235, HG00236, HG00237, HG00238, HG00239, HG00240, HG00242, HG00243, HG00244, HG00245, HG00246, HG00250, HG00251, HG00252, HG00253, HG00254, HG00255, HG00256, HG00257, HG00258, HG00259, HG00260, HG00261, ...]\n",
              "\n",
              "[2535 rows x 0 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSm4izy_bcDI",
        "outputId": "1c8ca165-b814-4d4a-d7bc-63a3312eb92c"
      },
      "source": [
        "%time samples_idx1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 5.48 µs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HG00096</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00097</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00099</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00101</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00258</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00259</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00260</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00261</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00262</th>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2535 rows × 0 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: [HG00096, HG00097, HG00099, HG00100, HG00101, HG00102, HG00103, HG00105, HG00106, HG00107, HG00108, HG00109, HG00110, HG00111, HG00112, HG00113, HG00114, HG00115, HG00116, HG00117, HG00118, HG00119, HG00120, HG00121, HG00122, HG00123, HG00124, HG00125, HG00126, HG00127, HG00128, HG00129, HG00130, HG00131, HG00132, HG00133, HG00136, HG00137, HG00138, HG00139, HG00140, HG00141, HG00142, HG00143, HG00145, HG00146, HG00148, HG00149, HG00150, HG00151, HG00154, HG00155, HG00157, HG00158, HG00159, HG00160, HG00171, HG00173, HG00174, HG00176, HG00177, HG00178, HG00179, HG00180, HG00181, HG00182, HG00183, HG00185, HG00186, HG00187, HG00188, HG00189, HG00190, HG00231, HG00232, HG00233, HG00234, HG00235, HG00236, HG00237, HG00238, HG00239, HG00240, HG00242, HG00243, HG00244, HG00245, HG00246, HG00250, HG00251, HG00252, HG00253, HG00254, HG00255, HG00256, HG00257, HG00258, HG00259, HG00260, HG00261, ...]\n",
              "\n",
              "[2535 rows x 0 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLhtE8Y3bcDI",
        "outputId": "83fa2cc3-aadf-4659-a6ca-77c82d903455"
      },
      "source": [
        "%time\n",
        "# ignore SettingWithCopyWarning errors\n",
        "pandas.options.mode.chained_assignment = None  # default='warn'\n",
        "# file containing all the sample labels (the population codes)\n",
        "popfile = \"igsr_samples.tsv\"\n",
        "\n",
        "with open(popfile, 'r') as pop:\n",
        "    pop_df = pandas.read_csv(pop, sep='\\t', header=0)\n",
        "\n",
        "# select the sample names and population codes to make a new data frame\n",
        "pop_class = pop_df[['Sample name', 'Population code']]\n",
        "\n",
        "# select the sample names and superpopulation codes to make a new data frame\n",
        "superpop_class = pop_df[['Sample name','Superpopulation code']]\n",
        "\n",
        "# set the sample names as index of pandas dataframe \n",
        "superpop_class.set_index('Sample name', inplace=True)\n",
        "superpop_class.sort_index(inplace=True)\n",
        "\n",
        "# create a new data frame by merging the label information with the existing sample IDs\n",
        "feature_labels = samples_idx.join(superpop_class)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 5.72 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLopenu1bcDJ",
        "outputId": "694436a4-0655-42b3-887d-1daf0a3b6745"
      },
      "source": [
        "%time feature_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 7.39 µs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Superpopulation code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HG00096</th>\n",
              "      <td>EUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00097</th>\n",
              "      <td>EUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00099</th>\n",
              "      <td>EUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00100</th>\n",
              "      <td>EUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HG00101</th>\n",
              "      <td>EUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21137</th>\n",
              "      <td>SAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21141</th>\n",
              "      <td>SAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21142</th>\n",
              "      <td>SAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21143</th>\n",
              "      <td>SAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NA21144</th>\n",
              "      <td>SAS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2535 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Superpopulation code\n",
              "HG00096                  EUR\n",
              "HG00097                  EUR\n",
              "HG00099                  EUR\n",
              "HG00100                  EUR\n",
              "HG00101                  EUR\n",
              "...                      ...\n",
              "NA21137                  SAS\n",
              "NA21141                  SAS\n",
              "NA21142                  SAS\n",
              "NA21143                  SAS\n",
              "NA21144                  SAS\n",
              "\n",
              "[2535 rows x 1 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzThxyGIbcDK",
        "outputId": "ce02baba-3e32-43c2-ddff-35f2fd7f316a"
      },
      "source": [
        "class_ratios = feature_labels['Superpopulation code'].value_counts()\n",
        "print(class_ratios)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AFR    669\n",
            "EAS    515\n",
            "EUR    505\n",
            "SAS    494\n",
            "AMR    352\n",
            "Name: Superpopulation code, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ9T8JX9bcDK",
        "outputId": "31d2b5b7-0c48-4381-8073-eff40ede7aef"
      },
      "source": [
        "%time\n",
        "import numpy as np\n",
        "\n",
        "opened = open(vcf_file, 'r')\n",
        "\n",
        "samples = samples_idx\n",
        "\n",
        "cnt = 0\n",
        "line = True\n",
        "while line:\n",
        "    line = opened.readline()\n",
        "\n",
        "    if not line.startswith('#') and line.strip():\n",
        "        # extract the sample genotypes from the row\n",
        "        rs_id = line.split('\\t')[2]\n",
        "        alleles = line.split('\\t')[9:]\n",
        "        alleles[-1] = alleles[-1].strip('\\n')\n",
        "\n",
        "        # label missing data as NAN\n",
        "        alleles = [x if not '.' in x.split('|') else np.NAN for x in alleles]\n",
        "        \n",
        "        # put the genotype info in certain order, i.e. the phasing is disregarded\n",
        "        alleles = ['|'.join(sorted(x.split('|'))) for x in alleles if x is not np.NAN]\n",
        "        \n",
        "        # add the feature (SNP) to the existing data frame\n",
        "        samples[rs_id] = alleles\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "opened.close()\n",
        "\n",
        "# drop the columns (features) with NAN values\n",
        "samples.dropna(axis=0, thresh=1, how=\"any\", inplace=True)\n",
        "\n",
        "# covert the categorical data (e.g. 1|0, 1|2) to numerical by one-hot-encoding\n",
        "features_df = pandas.get_dummies(samples)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 6.44 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5-h55UVbcDM",
        "outputId": "374d5f1c-03f1-4c2c-e7fc-5fb9282112e6"
      },
      "source": [
        "%time\n",
        "import cupy as cp\n",
        "\n",
        "opened = open(vcf_file, 'r')\n",
        "\n",
        "samples = samples_idx\n",
        "\n",
        "cnt = 0\n",
        "line = True\n",
        "while line:\n",
        "    line = opened.readline()\n",
        "\n",
        "    if not line.startswith('#') and line.strip():\n",
        "        # extract the sample genotypes from the row\n",
        "        rs_id = line.split('\\t')[2]\n",
        "        alleles = line.split('\\t')[9:]\n",
        "        alleles[-1] = alleles[-1].strip('\\n')\n",
        "\n",
        "        # label missing data as NAN\n",
        "        alleles = [x if not '.' in x.split('|') else cp.NAN for x in alleles]\n",
        "        \n",
        "        # put the genotype info in certain order, i.e. the phasing is disregarded\n",
        "        alleles = ['|'.join(sorted(x.split('|'))) for x in alleles if x is not cp.NAN]\n",
        "        \n",
        "        # add the feature (SNP) to the existing data frame\n",
        "        samples[rs_id] = alleles\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "opened.close()\n",
        "\n",
        "# drop the columns (features) with NAN values\n",
        "samples.dropna(axis=0, thresh=1, how=\"any\", inplace=True)\n",
        "\n",
        "# covert the categorical data (e.g. 1|0, 1|2) to numerical by one-hot-encoding\n",
        "features_df1 = pandas.get_dummies(samples)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 6.44 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8eDsZQnbcDN",
        "outputId": "c3c1b46f-54b7-4c4a-bd4d-09bfedd5c4cf"
      },
      "source": [
        "%timeit features_df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16.5 ns ± 0.0233 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDCweK05bcDV"
      },
      "source": [
        "# Compare the time it takes to covert the categorical data (e.g. 1|0, 1|2) to numerical by one-hot-encoding by the CPU and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5vpK74IbcDV",
        "outputId": "cac6a0d8-93a0-4f5c-e7df-cee5465b6f79"
      },
      "source": [
        "#%time\n",
        "import pandas\n",
        "import pandas as pd\n",
        "\n",
        "%timeit pandas.get_dummies(samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.4 s ± 2.77 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U61zsjnfbcDW",
        "outputId": "917429a1-2ed3-4db7-ebfc-b2bbdd3b06f2"
      },
      "source": [
        "#%time\n",
        "import cudf\n",
        "import pandas\n",
        "import pandas as pd\n",
        "\n",
        "features_dff = pandas.get_dummies(samples)\n",
        "gdf = cudf.DataFrame.from_pandas(features_dff)\n",
        "%timeit cudf.get_dummies(gdf)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.17 s ± 3.06 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmYiflnwbcDW"
      },
      "source": [
        "features_df = cudf.get_dummies(gdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDXvOICLbcDZ"
      },
      "source": [
        "# Can be observed that  the GPU considerably outperformed the CPU in terms if computational time\n",
        "# With the CPU (11.6 s ± 14.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) and GPU(1.16 s ± 1.49 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL6bmjPTbcDm",
        "outputId": "f1e05774-e8dd-4d58-946a-da8e69406fda"
      },
      "source": [
        "#Same time as CPU here because it is only returning the dataframe(variable)\n",
        "%timeit features_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19.2 ns ± 0.0313 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_sinf4MbcDn"
      },
      "source": [
        "################################################################ Random Forest Implementation using cuML #########################################################################\n",
        "########################################################################### That for CPU runs ####################################################################################\n",
        "############################################################################# needs some fixes ###################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKXRayH4bcDn"
      },
      "source": [
        "import cuml\n",
        "import cupy as cp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kdE6O7AubcDo",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "c38965c1-e62d-457c-a03d-11ab83bb37e9"
      },
      "source": [
        "## NB NOT fully fuctional and can be skipped. Does not affect the rest of the algorithms\n",
        "\n",
        "%time\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "from cuml.datasets.classification import make_classification\n",
        "from cuml.preprocessing.model_selection import train_test_split\n",
        "from cuml.ensemble import RandomForestClassifier as cuRF\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "features = cp.array(features_df1)\n",
        "labels = cp.array(feature_labels).ravel()\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.25,\n",
        "                                                                            random_state=42)\n",
        "\n",
        "#################################################################################################################################################################################\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 6.44 µs\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Unsupported dtype object",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-46bafe4f801d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_df1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/cupy/creation/from_data.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(obj, dtype, copy, order, subok, ndmin)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core._send_object_to_gpu\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unsupported dtype object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJnyyukmbcDp"
      },
      "source": [
        "############################################################################ CPU implementation of RF ###########################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaT-jp3ObcDp",
        "outputId": "ac1029f4-51aa-4ac8-d1e8-6bab1fda32ae"
      },
      "source": [
        "%time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = np.array(features_df)\n",
        "\n",
        "\n",
        "labels = np.array(feature_labels).ravel()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.25,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 6.44 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdjdkKhkbcDq",
        "outputId": "aa69a306-4e41-436f-8fc9-cb44c4f13736"
      },
      "source": [
        "# do hyperparameter tuning on with RandomForestClassifier on our data set\n",
        "%time\n",
        "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \"n_estimators\": [100, 400, 700, 1000, 1500]}\n",
        "param_grid = { \"criterion\" : [\"gini\", \"entropy\"] , \"min_samples_leaf\" : [1,20,25,50], \"min_samples_split\" : [2,12,25], \"n_estimators\": [500, 1000, 1500]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "# define random forest model\n",
        "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=42, n_jobs=-1)\n",
        "# method to test out all the combinations of the parameters\n",
        "clf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n",
        "\n",
        "# fit the features and labels \n",
        "clf.fit(train_features, train_labels)\n",
        "# print the best parameters\n",
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 6.44 µs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 500}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX4v1CdubcDq"
      },
      "source": [
        "#From the hyper-parametric tuning the above parameters were found to be the best combination of parameters to yield the best results for Random Forest classifier.\n",
        "#****************************************************************'criterion': 'gini',***********************************************************************************\n",
        "#****************************************************************'min_samples_leaf': 1,*********************************************************************************\n",
        "#****************************************************************'min_samples_split': 2,******************************************************************************** \n",
        "#****************************************************************'n_estimators': 500} **********************************************************************************\n",
        "\n",
        "\n",
        "#Model is defined with the parameters from the hyperparametric tunning \n",
        "#kept trying different n_estimators to achieve a better model.\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=1500, criterion='gini', min_samples_leaf=1, min_samples_split=12, max_features='auto', oob_score=True, random_state=42, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLe1BvxIbcDr",
        "outputId": "790bb8ee-3916-4d31-baff-2febcb0a84ed"
      },
      "source": [
        "# Use traditional train-test-split to compare with K-fold cross validation baseline and make classification report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "feature_list = features_df.columns\n",
        "\n",
        "\n",
        "# print dimensions to check if all is ok\n",
        "print('Training Features Shape:', train_features.shape)\n",
        "print('Training Labels Shape:', train_labels.shape)\n",
        "print('Testing Features Shape:', test_features.shape)\n",
        "print('Testing Labels Shape:', test_labels.shape)\n",
        "\n",
        "train_labels = train_labels.ravel()\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(train_features, train_labels)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(test_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Features Shape: (1901, 29762)\n",
            "Training Labels Shape: (1901,)\n",
            "Testing Features Shape: (634, 29762)\n",
            "Testing Labels Shape: (634,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpnAcVA2bcDr",
        "outputId": "014d1b56-f922-4fc2-ca8a-4ed4bc19d4d0"
      },
      "source": [
        "# print scores and classification report\n",
        "\n",
        "# change dimension of labels to compute accuracy\n",
        "test_labels = test_labels.ravel()\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "print('accuracy: {}'.format(round(accuracy, 4)))\n",
        "\n",
        "# print score ()\n",
        "score = rf.score(train_features, train_labels)\n",
        "print('score: {}'.format(round(score, 4)))\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(test_labels, predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.3596\n",
            "score: 0.979\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AFR       0.36      0.71      0.48       152\n",
            "         AMR       0.27      0.05      0.08        87\n",
            "         EAS       0.37      0.16      0.23       142\n",
            "         EUR       0.34      0.44      0.39       117\n",
            "         SAS       0.39      0.30      0.34       136\n",
            "\n",
            "    accuracy                           0.36       634\n",
            "   macro avg       0.35      0.33      0.30       634\n",
            "weighted avg       0.35      0.36      0.32       634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLFhlbt1bcDs"
      },
      "source": [
        "#Feature selection. From the initial poor results obtained a closer detail to the data will reveal that is has too many features and as such \n",
        "#that has resulted in a lot of noise. It is thus imperative, from this, to remove the unimportant features(noise) in order to increase the performace \n",
        "#of the model. A threshold of the top 100 features (SNPs) were subsetted and used to retrain the model\n",
        "# using a Univariate selection method and selectk class from the sciKit library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb_yZByqut5C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfpU-HjjbcDs"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from numpy import set_printoptions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeaUJrjcbcDs",
        "outputId": "b3360e62-52c0-4c5e-f970-8ebcc84356fa"
      },
      "source": [
        "X = train_features\n",
        "Y = train_labels\n",
        "\n",
        "# feature extraction\n",
        "test = SelectKBest(score_func=f_classif, k=700)\n",
        "fit = test.fit(X, Y)\n",
        "\n",
        "# summarize scores\n",
        "set_printoptions(precision=3)\n",
        "print(fit.scores_)\n",
        "\n",
        "#Prints the index of the features that were selected as important\n",
        "print(fit.get_support(indices=True))\n",
        "\n",
        "features = fit.transform(X)\n",
        "\n",
        "\n",
        "#Reduce X to the selected features\n",
        "selected_Features = fit.transform(X)\n",
        "\n",
        "#Reduce the test set to contain only the selected features as well\n",
        "selected_Features_Test = fit.transform(test_features)\n",
        "\n",
        "print(selected_Features)\n",
        "\n",
        "selected_Features.shape\n",
        "selected_Features_Test.shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 8.147 11.135  2.794 ...  1.722  1.404  1.405]\n",
            "[   79    80   166   167   168   249   250   292   329   330   367   368\n",
            "   396   397   455   456   724   886   887   990  1291  1292  1307  1482\n",
            "  1634  1719  1981  1982  1983  2101  2102  2295  2773  2928  2929  3210\n",
            "  3212  3877  3879  4170  4191  4193  4764  4765  4835  4836  4988  5088\n",
            "  5091  5092  5125  5126  5214  5327  5328  5352  5353  5402  5417  5419\n",
            "  5540  5541  5626  5627  5665  5898  5899  6141  6142  6151  6187  6188\n",
            "  6444  6572  6574  6971  7205  7206  7232  7233  7243  7244  7307  7308\n",
            "  7334  7335  7363  7364  7368  7369  7383  7384  7388  7458  7459  7505\n",
            "  7506  7600  7615  7616  7723  7724  7725  7776  7778  7808  7810  7840\n",
            "  7847  7893  7898  7905  7907  7914  7943  7946  7957  7982  8025  8082\n",
            "  8088  8103  8124  8174  8176  8186  8193  8200  8216  8267  8338  8393\n",
            "  8409  8436  8438  8439  8485  8487  8529  8532  8535  8542  8590  8747\n",
            "  8749  8875  8877  9104  9165  9166  9421  9509  9515  9516  9538  9539\n",
            "  9575  9629  9852  9853  9904  9914  9915 10205 10207 10272 10274 10290\n",
            " 10291 10300 10301 10303 10304 10310 10323 10324 10341 10342 10346 10347\n",
            " 10349 10364 10366 10383 10385 10398 10400 10458 10460 10533 10534 10768\n",
            " 10828 10830 10843 10891 10892 10924 10925 10969 10970 10972 10973 11040\n",
            " 11041 11150 11236 11276 11518 11519 11526 11660 11661 11922 11924 11964\n",
            " 11966 11999 12001 12309 12310 12361 12363 12366 12368 12423 12425 12742\n",
            " 13479 13570 13571 13628 13629 13674 13852 14534 14633 14634 14747 14803\n",
            " 14804 14813 14814 14850 14851 14895 14904 14905 15065 15068 15099 15100\n",
            " 15122 15123 15183 15184 15197 15198 15411 15644 15647 15795 15806 15846\n",
            " 15855 15856 15858 15859 15863 15864 15885 15890 15897 15898 15911 15915\n",
            " 15916 15918 15919 15941 15942 15983 16003 16004 16028 16035 16036 16061\n",
            " 16062 16068 16069 16105 16130 16149 16203 16307 16328 16349 16350 16354\n",
            " 16359 16478 16481 16504 16708 16709 16751 16762 16763 16826 16827 16834\n",
            " 16942 16944 16972 16973 16977 16978 17017 17018 17084 17089 17090 17092\n",
            " 17093 17170 17248 17249 17253 17392 17445 17446 17463 17486 17487 17504\n",
            " 17689 18010 18409 19007 19013 19608 19609 19941 19943 20022 20024 20025\n",
            " 20027 20036 20037 20056 20058 20484 20490 20491 20518 20521 20524 20525\n",
            " 20526 20531 20532 20534 20537 20540 20543 20549 20550 20559 20594 20618\n",
            " 20620 20621 20623 20715 20717 20722 20742 20744 20852 20872 20884 20976\n",
            " 20977 21034 21035 21048 21049 21056 21057 21088 21090 21091 21093 21285\n",
            " 21286 21295 21296 21435 21437 21483 21484 21510 21511 21611 21623 21630\n",
            " 21788 21789 21840 21841 21978 21979 21994 22030 22031 22160 22161 22320\n",
            " 22321 22440 22551 22554 22591 22638 22639 22645 22646 22655 22656 22719\n",
            " 22720 22727 22728 22743 22781 22782 22824 22825 22859 22860 22876 22877\n",
            " 22890 22891 22910 22911 22916 22925 22940 22941 22947 22948 22968 22969\n",
            " 23023 23024 23030 23031 23040 23041 23115 23116 23120 23121 23135 23136\n",
            " 23176 23177 23232 23233 23281 23282 23304 23305 23315 23316 23345 23346\n",
            " 23368 23370 23385 23386 23398 23399 23404 23405 23528 23602 23603 23814\n",
            " 23831 23834 23845 23939 23956 23958 23959 23961 23993 23995 24015 24030\n",
            " 24148 24149 24196 24197 24342 24432 24434 24507 24571 24572 24574 24585\n",
            " 24586 24644 24645 24677 24678 24679 24686 24806 24807 24808 24810 24811\n",
            " 24854 24869 24882 24885 24958 24959 24991 24992 25079 25080 25096 25097\n",
            " 25104 25105 25109 25110 25136 25137 25185 25186 25187 25209 25210 25235\n",
            " 25274 25279 25318 25323 25330 25331 25333 25334 25434 25556 25558 25559\n",
            " 25579 25580 25626 25692 25702 25703 25812 25910 25911 26012 26024 26102\n",
            " 26205 26207 26279 26315 26323 26344 26380 26402 26403 26411 26446 26451\n",
            " 26466 26474 26475 26476 26479 26490 26519 26522 26527 26528 26541 26635\n",
            " 26773 26824 26825 26869 26880 26945 27043 27051 27052 27059 27072 27117\n",
            " 27122 27127 27135 27143 27146 27156 27159 27169 27170 27181 27183 27186\n",
            " 27187 27188 27198 27232 27323 27346 27347 27362 27363 27364 27369 27370\n",
            " 27371 27412 27413 27466 27689 27690 27774 27775 27855 27908 27909 27932\n",
            " 27933 27995 27996 28010 28011 28118 28148 28241 28299 28326 28335 28471\n",
            " 28473 28510 28511 28570 28572 28631 28723 28725 28792 28795 28959 28960\n",
            " 28961 28980 28983 29007 29064 29066 29080 29081 29116 29125 29136 29139\n",
            " 29159 29206 29218 29220 29253 29305 29340 29342 29361 29362 29380 29408\n",
            " 29531 29533 29545 29620]\n",
            "[[1 0 0 ... 1 0 0]\n",
            " [1 0 0 ... 1 1 0]\n",
            " [1 0 0 ... 1 1 0]\n",
            " ...\n",
            " [1 0 1 ... 1 1 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " [0 1 0 ... 1 0 0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:115: UserWarning: Features [   57    58   124 ... 29740 29751 29752] are constant.\n",
            "  UserWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(634, 700)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awNkTm1SbcDt",
        "outputId": "5c39d18f-2d07-4f3d-bac0-4ccfd515c774"
      },
      "source": [
        "################################################# Redo hyperparametric tuning since the feature size has been drastically reduced ################################################\n",
        "\n",
        "# do hyperparameter tuning on with RandomForestClassifier on our data set\n",
        "%time\n",
        "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \"n_estimators\": [100, 400, 700, 1000, 1500]}\n",
        "param_grid = { \"criterion\" : [\"gini\", \"entropy\"] , \"min_samples_leaf\" : [1,20,25,50], \"min_samples_split\" : [2,12,13,15,25], \"n_estimators\": [500, 750,900, 1000, 1500, 2000]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "# define random forest model\n",
        "rf_1 = RandomForestClassifier(max_features='auto', oob_score=True, random_state=42, n_jobs=-1)\n",
        "\n",
        "# method to test out all the combinations of the parameters\n",
        "clf_1 = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n",
        "\n",
        "# fit the features and labels \n",
        "clf_1.fit(selected_Features, train_labels)\n",
        "# print the best parameters\n",
        "clf_1.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
            "Wall time: 7.15 µs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 12,\n",
              " 'n_estimators': 750}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuxP7gVcut5D"
      },
      "source": [
        "rf_1 = RandomForestClassifier(n_estimators=750, criterion='entropy', min_samples_leaf=1, min_samples_split=12, max_features='auto', oob_score=True, random_state=42, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZGUZDiYbcDt",
        "outputId": "e5ae7034-bedd-4c04-f45c-b92c576c30f5"
      },
      "source": [
        "####################################################################### Re-Run RF Model with selected Features ###################################################################\n",
        "\n",
        "rf_1 = RandomForestClassifier(n_estimators=500, criterion='gini', min_samples_leaf=1, min_samples_split=12, max_features= 100, oob_score=True, random_state=42, n_jobs=-1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#feature_list = features_df.columns\n",
        "\n",
        "train_labels = train_labels.ravel()\n",
        "\n",
        "# Train the model on training data\n",
        "rf_1.fit(selected_Features, train_labels)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions_1 =rf_1.predict(selected_Features_Test)\n",
        "\n",
        "\n",
        "# print dimensions to check if all is ok\n",
        "print('Training Features Shape:', selected_Features.shape)\n",
        "print('Training Labels Shape:', train_labels.shape)\n",
        "print('Testing Features Shape:', selected_Features_Test.shape)\n",
        "print('Testing Labels Shape:', test_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Features Shape: (1901, 700)\n",
            "Training Labels Shape: (1901,)\n",
            "Testing Features Shape: (634, 700)\n",
            "Testing Labels Shape: (634,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmsZbUn_bcDt",
        "outputId": "683d82ac-4deb-46f5-b3a8-7e798e421bb8"
      },
      "source": [
        "# print scores and classification report\n",
        "\n",
        "# change dimension of labels to compute accuracy\n",
        "test_labels = test_labels.ravel()\n",
        "accuracy = accuracy_score(test_labels, predictions_1)\n",
        "\n",
        "print('accuracy: {}'.format(round(accuracy, 4)))\n",
        "\n",
        "# print score ()\n",
        "score = rf_1.score(selected_Features, train_labels)\n",
        "print('score: {}'.format(round(score, 4)))\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(test_labels, predictions_1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.3549\n",
            "score: 0.9158\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AFR       0.36      0.66      0.46       152\n",
            "         AMR       0.24      0.10      0.15        87\n",
            "         EAS       0.42      0.22      0.29       142\n",
            "         EUR       0.33      0.40      0.36       117\n",
            "         SAS       0.38      0.28      0.32       136\n",
            "\n",
            "    accuracy                           0.35       634\n",
            "   macro avg       0.35      0.33      0.32       634\n",
            "weighted avg       0.36      0.35      0.33       634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0x5v0Wrcihz",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8ddc39ec-6af3-4e2d-c54a-e013796cb86c"
      },
      "source": [
        "#Multinomial Naïve Bayes \n",
        "import numpy as np\n",
        "#rng = np.random.RandomState(1)\n",
        "#X = rng.randint(5, size=(6, 100))\n",
        "#y = np.array([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "MNBclf = MultinomialNB()\n",
        "MNBclf.fit(selected_Features, train_labels)\n",
        "\n",
        "print((MNBclf.predict(selected_Features_Test)))\n",
        "y_pred= MNBclf.predict(selected_Features_Test)\n",
        "\n",
        "#check Accuracy score\n",
        "from sklearn import metrics\n",
        "metrics.accuracy_score(test_labels, y_pred)\n",
        "\n",
        "#print('Model accuracy score: {0:0.4f}'. format(accuracy_score(selected_Features, y_pred)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AMR' 'EUR' 'AMR' 'AMR' 'AFR' 'AMR' 'SAS' 'AFR' 'AMR' 'AFR' 'AMR' 'AMR'\n",
            " 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR' 'EUR' 'AFR' 'EUR'\n",
            " 'AMR' 'EUR' 'EAS' 'AFR' 'AMR' 'EUR' 'AMR' 'EUR' 'AMR' 'AMR' 'EUR' 'EUR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'SAS' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'EUR' 'AFR' 'AMR' 'AMR' 'AMR' 'AFR' 'SAS' 'AMR' 'AFR' 'EUR' 'AMR'\n",
            " 'EAS' 'AMR' 'AMR' 'AMR' 'AFR' 'EUR' 'AMR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AFR' 'SAS' 'AMR' 'AMR' 'AMR' 'AMR'\n",
            " 'EUR' 'EUR' 'AMR' 'AMR' 'SAS' 'SAS' 'AMR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR'\n",
            " 'AMR' 'EUR' 'SAS' 'EUR' 'EUR' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'EUR' 'EUR' 'AFR' 'EAS' 'EUR' 'AMR' 'SAS' 'AMR' 'EUR' 'AMR' 'EUR'\n",
            " 'SAS' 'EUR' 'EUR' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR'\n",
            " 'AMR' 'SAS' 'SAS' 'SAS' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR'\n",
            " 'AMR' 'AFR' 'AMR' 'EUR' 'EUR' 'AMR' 'AFR' 'EAS' 'EUR' 'AMR' 'AMR' 'EUR'\n",
            " 'SAS' 'AMR' 'EUR' 'EUR' 'AMR' 'AMR' 'EUR' 'AMR' 'EUR' 'AMR' 'EUR' 'AMR'\n",
            " 'AMR' 'AMR' 'EAS' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'EUR' 'EUR' 'AMR' 'AMR'\n",
            " 'AMR' 'EUR' 'AMR' 'AMR' 'EUR' 'EAS' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AFR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'SAS' 'EUR' 'AMR' 'AMR'\n",
            " 'AFR' 'AMR' 'EUR' 'EUR' 'AMR' 'AFR' 'EUR' 'AMR' 'AMR' 'AFR' 'AMR' 'EUR'\n",
            " 'EAS' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'EUR' 'AMR' 'EUR' 'AMR'\n",
            " 'AFR' 'AFR' 'AMR' 'AMR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR' 'EUR' 'AFR'\n",
            " 'AMR' 'AMR' 'EUR' 'EUR' 'EUR' 'EUR' 'EUR' 'EUR' 'AMR' 'EUR' 'AMR' 'AFR'\n",
            " 'EUR' 'AFR' 'AFR' 'AMR' 'EUR' 'EAS' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR'\n",
            " 'EUR' 'AMR' 'EUR' 'AMR' 'AMR' 'AMR' 'AFR' 'EUR' 'AMR' 'AMR' 'AFR' 'AMR'\n",
            " 'EUR' 'EUR' 'AMR' 'AMR' 'EUR' 'AFR' 'SAS' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR'\n",
            " 'SAS' 'AMR' 'EUR' 'AMR' 'SAS' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'EUR'\n",
            " 'AFR' 'EUR' 'EAS' 'SAS' 'EUR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'EUR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'AFR' 'AMR' 'EUR' 'EUR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'EUR' 'AFR' 'AFR' 'EUR' 'AMR' 'AMR'\n",
            " 'EUR' 'AMR' 'EUR' 'AMR' 'AMR' 'AFR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'EAS' 'EUR' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'EUR' 'EAS' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AFR' 'AMR' 'EUR'\n",
            " 'AMR' 'AFR' 'EUR' 'AMR' 'AMR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR' 'AMR'\n",
            " 'SAS' 'AMR' 'AFR' 'EUR' 'AMR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'AFR' 'AMR'\n",
            " 'AMR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR' 'EUR'\n",
            " 'EUR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'EAS' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR' 'AMR'\n",
            " 'AMR' 'AMR' 'EUR' 'EUR' 'EUR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'EUR'\n",
            " 'EUR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR'\n",
            " 'AMR' 'EUR' 'AMR' 'EUR' 'EUR' 'EUR' 'AMR' 'EAS' 'AMR' 'EUR' 'SAS' 'EUR'\n",
            " 'AFR' 'EUR' 'AMR' 'SAS' 'AMR' 'AMR' 'EUR' 'EUR' 'SAS' 'AMR' 'AMR' 'EUR'\n",
            " 'EUR' 'EUR' 'AMR' 'SAS' 'AMR' 'EUR' 'AFR' 'AFR' 'AMR' 'AFR' 'AMR' 'AFR'\n",
            " 'AMR' 'EUR' 'AMR' 'EUR' 'AMR' 'EUR' 'EUR' 'AFR' 'AFR' 'AMR' 'AMR' 'AMR'\n",
            " 'AFR' 'AMR' 'AMR' 'AMR' 'AMR' 'AFR' 'EUR' 'EUR' 'EUR' 'AMR' 'AMR' 'AMR'\n",
            " 'EUR' 'EUR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'EUR' 'AFR' 'AFR' 'AMR' 'AFR'\n",
            " 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'EUR' 'AFR' 'AMR' 'AFR' 'AMR'\n",
            " 'AMR' 'AMR' 'AFR' 'EUR' 'EUR' 'SAS' 'EUR' 'AMR' 'AFR' 'AFR' 'AMR' 'AMR'\n",
            " 'EUR' 'AMR' 'EUR' 'EUR' 'AMR' 'AMR' 'SAS' 'EAS' 'AMR' 'AMR' 'AMR' 'EUR'\n",
            " 'AMR' 'AMR' 'EAS' 'EUR' 'EUR' 'AMR' 'SAS' 'AMR' 'EUR' 'EUR' 'AMR' 'EUR'\n",
            " 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'SAS'\n",
            " 'EUR' 'AMR' 'EUR' 'AMR' 'AMR' 'AMR' 'AMR' 'EUR' 'AMR' 'AMR' 'EUR' 'EUR'\n",
            " 'EUR' 'AMR' 'AMR' 'EUR' 'AFR' 'EUR' 'AMR' 'AFR' 'AMR' 'AMR' 'AMR' 'EUR'\n",
            " 'AMR' 'AFR' 'AMR' 'AMR' 'SAS' 'AMR' 'EUR' 'AMR' 'AMR' 'AMR']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.23501577287066247"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIk_l-A_cea-",
        "outputId": "b3437005-d016-482c-c35f-4f424a2e5608"
      },
      "source": [
        "# print the confusion matrix\n",
        "metrics.confusion_matrix(test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[18, 89,  6, 35,  4],\n",
              "       [ 8, 67,  1,  7,  4],\n",
              "       [12, 77,  4, 43,  6],\n",
              "       [11, 47,  1, 52,  6],\n",
              "       [17, 80,  3, 28,  8]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "APE7cx5DcaEi",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "6d663807-eefd-419e-b1ab-b4b3b4feb7f4"
      },
      "source": [
        "# Feature Extraction with PCA\n",
        "import numpy\n",
        "from pandas import read_csv\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# load data\n",
        "X = train_features\n",
        "Y = train_labels\n",
        "\n",
        "# feature extraction\n",
        "pca = PCA(n_components=1000)\n",
        "fit = pca.fit(X)\n",
        "\n",
        "# summarize components\n",
        "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
        "print(fit.components_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Explained Variance: [1.164e-01 4.786e-02 3.839e-02 3.389e-02 2.890e-02 2.136e-02 1.969e-02\n",
            " 1.498e-02 1.466e-02 1.383e-02 1.261e-02 1.202e-02 1.136e-02 1.038e-02\n",
            " 1.007e-02 9.617e-03 9.095e-03 8.758e-03 8.427e-03 8.119e-03 7.909e-03\n",
            " 7.348e-03 6.846e-03 6.800e-03 6.539e-03 6.320e-03 6.168e-03 5.930e-03\n",
            " 5.648e-03 5.221e-03 4.939e-03 4.771e-03 4.637e-03 4.430e-03 4.322e-03\n",
            " 4.190e-03 4.096e-03 3.911e-03 3.790e-03 3.756e-03 3.647e-03 3.616e-03\n",
            " 3.575e-03 3.413e-03 3.357e-03 3.305e-03 3.192e-03 3.136e-03 3.077e-03\n",
            " 2.995e-03 2.901e-03 2.883e-03 2.843e-03 2.750e-03 2.744e-03 2.701e-03\n",
            " 2.630e-03 2.576e-03 2.531e-03 2.505e-03 2.465e-03 2.413e-03 2.376e-03\n",
            " 2.367e-03 2.339e-03 2.276e-03 2.205e-03 2.194e-03 2.157e-03 2.148e-03\n",
            " 2.108e-03 2.080e-03 2.062e-03 2.035e-03 2.004e-03 1.994e-03 1.965e-03\n",
            " 1.936e-03 1.925e-03 1.878e-03 1.845e-03 1.838e-03 1.830e-03 1.810e-03\n",
            " 1.805e-03 1.767e-03 1.752e-03 1.738e-03 1.717e-03 1.692e-03 1.646e-03\n",
            " 1.622e-03 1.612e-03 1.599e-03 1.574e-03 1.553e-03 1.543e-03 1.502e-03\n",
            " 1.489e-03 1.470e-03 1.466e-03 1.454e-03 1.427e-03 1.413e-03 1.407e-03\n",
            " 1.404e-03 1.387e-03 1.375e-03 1.369e-03 1.366e-03 1.346e-03 1.336e-03\n",
            " 1.312e-03 1.301e-03 1.295e-03 1.284e-03 1.266e-03 1.264e-03 1.251e-03\n",
            " 1.242e-03 1.236e-03 1.217e-03 1.204e-03 1.195e-03 1.186e-03 1.180e-03\n",
            " 1.160e-03 1.156e-03 1.147e-03 1.140e-03 1.130e-03 1.118e-03 1.111e-03\n",
            " 1.110e-03 1.089e-03 1.084e-03 1.077e-03 1.073e-03 1.071e-03 1.064e-03\n",
            " 1.052e-03 1.048e-03 1.041e-03 1.031e-03 1.024e-03 1.020e-03 1.012e-03\n",
            " 1.009e-03 1.002e-03 9.899e-04 9.858e-04 9.788e-04 9.595e-04 9.566e-04\n",
            " 9.489e-04 9.452e-04 9.387e-04 9.379e-04 9.346e-04 9.323e-04 9.202e-04\n",
            " 9.161e-04 9.100e-04 9.000e-04 8.948e-04 8.922e-04 8.800e-04 8.780e-04\n",
            " 8.735e-04 8.699e-04 8.622e-04 8.614e-04 8.531e-04 8.480e-04 8.410e-04\n",
            " 8.320e-04 8.272e-04 8.240e-04 8.151e-04 8.130e-04 8.092e-04 8.036e-04\n",
            " 7.992e-04 7.963e-04 7.881e-04 7.839e-04 7.806e-04 7.781e-04 7.742e-04\n",
            " 7.699e-04 7.669e-04 7.621e-04 7.586e-04 7.544e-04 7.499e-04 7.482e-04\n",
            " 7.408e-04 7.366e-04 7.334e-04 7.307e-04 7.279e-04 7.262e-04 7.200e-04\n",
            " 7.162e-04 7.134e-04 7.039e-04 7.001e-04 6.961e-04 6.914e-04 6.904e-04\n",
            " 6.868e-04 6.848e-04 6.752e-04 6.716e-04 6.699e-04 6.685e-04 6.623e-04\n",
            " 6.586e-04 6.568e-04 6.545e-04 6.517e-04 6.494e-04 6.451e-04 6.430e-04\n",
            " 6.395e-04 6.362e-04 6.331e-04 6.318e-04 6.275e-04 6.261e-04 6.217e-04\n",
            " 6.198e-04 6.185e-04 6.149e-04 6.110e-04 6.095e-04 6.057e-04 6.030e-04\n",
            " 5.997e-04 5.977e-04 5.949e-04 5.903e-04 5.865e-04 5.829e-04 5.808e-04\n",
            " 5.793e-04 5.775e-04 5.765e-04 5.730e-04 5.665e-04 5.660e-04 5.630e-04\n",
            " 5.600e-04 5.575e-04 5.569e-04 5.530e-04 5.513e-04 5.493e-04 5.468e-04\n",
            " 5.433e-04 5.422e-04 5.405e-04 5.373e-04 5.351e-04 5.333e-04 5.312e-04\n",
            " 5.287e-04 5.263e-04 5.228e-04 5.194e-04 5.190e-04 5.181e-04 5.157e-04\n",
            " 5.138e-04 5.103e-04 5.075e-04 5.070e-04 5.045e-04 5.024e-04 5.002e-04\n",
            " 4.979e-04 4.975e-04 4.925e-04 4.915e-04 4.899e-04 4.869e-04 4.850e-04\n",
            " 4.819e-04 4.805e-04 4.795e-04 4.768e-04 4.745e-04 4.726e-04 4.703e-04\n",
            " 4.690e-04 4.665e-04 4.649e-04 4.644e-04 4.612e-04 4.588e-04 4.571e-04\n",
            " 4.556e-04 4.544e-04 4.519e-04 4.515e-04 4.489e-04 4.470e-04 4.444e-04\n",
            " 4.437e-04 4.424e-04 4.393e-04 4.375e-04 4.365e-04 4.346e-04 4.333e-04\n",
            " 4.315e-04 4.304e-04 4.285e-04 4.274e-04 4.241e-04 4.232e-04 4.209e-04\n",
            " 4.207e-04 4.203e-04 4.159e-04 4.147e-04 4.119e-04 4.111e-04 4.098e-04\n",
            " 4.086e-04 4.078e-04 4.057e-04 4.051e-04 4.041e-04 4.014e-04 3.980e-04\n",
            " 3.976e-04 3.959e-04 3.946e-04 3.931e-04 3.910e-04 3.902e-04 3.880e-04\n",
            " 3.868e-04 3.851e-04 3.842e-04 3.822e-04 3.802e-04 3.790e-04 3.771e-04\n",
            " 3.766e-04 3.743e-04 3.732e-04 3.722e-04 3.697e-04 3.685e-04 3.673e-04\n",
            " 3.651e-04 3.639e-04 3.625e-04 3.611e-04 3.598e-04 3.585e-04 3.576e-04\n",
            " 3.565e-04 3.553e-04 3.545e-04 3.534e-04 3.515e-04 3.500e-04 3.479e-04\n",
            " 3.475e-04 3.460e-04 3.441e-04 3.430e-04 3.422e-04 3.416e-04 3.407e-04\n",
            " 3.395e-04 3.386e-04 3.380e-04 3.346e-04 3.345e-04 3.333e-04 3.329e-04\n",
            " 3.306e-04 3.299e-04 3.288e-04 3.278e-04 3.270e-04 3.255e-04 3.236e-04\n",
            " 3.223e-04 3.215e-04 3.201e-04 3.197e-04 3.181e-04 3.174e-04 3.160e-04\n",
            " 3.153e-04 3.138e-04 3.120e-04 3.115e-04 3.109e-04 3.099e-04 3.076e-04\n",
            " 3.071e-04 3.065e-04 3.044e-04 3.039e-04 3.028e-04 3.021e-04 2.999e-04\n",
            " 2.996e-04 2.982e-04 2.977e-04 2.969e-04 2.961e-04 2.942e-04 2.938e-04\n",
            " 2.931e-04 2.915e-04 2.905e-04 2.889e-04 2.883e-04 2.879e-04 2.863e-04\n",
            " 2.859e-04 2.846e-04 2.838e-04 2.831e-04 2.813e-04 2.803e-04 2.796e-04\n",
            " 2.785e-04 2.776e-04 2.773e-04 2.757e-04 2.745e-04 2.741e-04 2.726e-04\n",
            " 2.722e-04 2.712e-04 2.700e-04 2.693e-04 2.690e-04 2.672e-04 2.660e-04\n",
            " 2.655e-04 2.642e-04 2.634e-04 2.619e-04 2.607e-04 2.604e-04 2.600e-04\n",
            " 2.591e-04 2.584e-04 2.578e-04 2.577e-04 2.568e-04 2.554e-04 2.549e-04\n",
            " 2.541e-04 2.536e-04 2.524e-04 2.503e-04 2.501e-04 2.493e-04 2.487e-04\n",
            " 2.480e-04 2.478e-04 2.469e-04 2.462e-04 2.449e-04 2.445e-04 2.443e-04\n",
            " 2.427e-04 2.421e-04 2.408e-04 2.401e-04 2.388e-04 2.374e-04 2.370e-04\n",
            " 2.359e-04 2.358e-04 2.349e-04 2.341e-04 2.332e-04 2.329e-04 2.315e-04\n",
            " 2.308e-04 2.301e-04 2.295e-04 2.288e-04 2.287e-04 2.269e-04 2.268e-04\n",
            " 2.261e-04 2.255e-04 2.244e-04 2.241e-04 2.232e-04 2.229e-04 2.226e-04\n",
            " 2.219e-04 2.195e-04 2.190e-04 2.183e-04 2.179e-04 2.173e-04 2.164e-04\n",
            " 2.153e-04 2.146e-04 2.143e-04 2.133e-04 2.123e-04 2.121e-04 2.112e-04\n",
            " 2.110e-04 2.101e-04 2.093e-04 2.087e-04 2.079e-04 2.070e-04 2.069e-04\n",
            " 2.056e-04 2.053e-04 2.047e-04 2.041e-04 2.031e-04 2.026e-04 2.023e-04\n",
            " 2.014e-04 2.009e-04 2.002e-04 1.995e-04 1.988e-04 1.986e-04 1.980e-04\n",
            " 1.978e-04 1.972e-04 1.962e-04 1.957e-04 1.955e-04 1.943e-04 1.943e-04\n",
            " 1.934e-04 1.922e-04 1.921e-04 1.919e-04 1.900e-04 1.898e-04 1.893e-04\n",
            " 1.889e-04 1.880e-04 1.872e-04 1.867e-04 1.862e-04 1.861e-04 1.854e-04\n",
            " 1.841e-04 1.839e-04 1.832e-04 1.826e-04 1.824e-04 1.823e-04 1.819e-04\n",
            " 1.813e-04 1.809e-04 1.802e-04 1.797e-04 1.793e-04 1.785e-04 1.781e-04\n",
            " 1.775e-04 1.774e-04 1.769e-04 1.762e-04 1.760e-04 1.750e-04 1.747e-04\n",
            " 1.742e-04 1.735e-04 1.732e-04 1.725e-04 1.722e-04 1.715e-04 1.709e-04\n",
            " 1.705e-04 1.703e-04 1.692e-04 1.692e-04 1.687e-04 1.682e-04 1.676e-04\n",
            " 1.671e-04 1.668e-04 1.661e-04 1.657e-04 1.649e-04 1.642e-04 1.639e-04\n",
            " 1.638e-04 1.631e-04 1.622e-04 1.621e-04 1.614e-04 1.611e-04 1.605e-04\n",
            " 1.602e-04 1.598e-04 1.593e-04 1.589e-04 1.585e-04 1.573e-04 1.571e-04\n",
            " 1.566e-04 1.562e-04 1.556e-04 1.553e-04 1.547e-04 1.547e-04 1.538e-04\n",
            " 1.536e-04 1.530e-04 1.527e-04 1.526e-04 1.521e-04 1.518e-04 1.513e-04\n",
            " 1.507e-04 1.504e-04 1.494e-04 1.491e-04 1.487e-04 1.484e-04 1.481e-04\n",
            " 1.475e-04 1.473e-04 1.466e-04 1.464e-04 1.456e-04 1.454e-04 1.453e-04\n",
            " 1.444e-04 1.441e-04 1.436e-04 1.435e-04 1.427e-04 1.425e-04 1.423e-04\n",
            " 1.421e-04 1.412e-04 1.407e-04 1.403e-04 1.400e-04 1.396e-04 1.394e-04\n",
            " 1.391e-04 1.380e-04 1.379e-04 1.376e-04 1.373e-04 1.365e-04 1.362e-04\n",
            " 1.357e-04 1.352e-04 1.346e-04 1.346e-04 1.341e-04 1.337e-04 1.336e-04\n",
            " 1.332e-04 1.328e-04 1.323e-04 1.320e-04 1.317e-04 1.317e-04 1.313e-04\n",
            " 1.306e-04 1.304e-04 1.303e-04 1.302e-04 1.296e-04 1.293e-04 1.285e-04\n",
            " 1.284e-04 1.281e-04 1.274e-04 1.271e-04 1.269e-04 1.263e-04 1.260e-04\n",
            " 1.257e-04 1.254e-04 1.252e-04 1.250e-04 1.245e-04 1.242e-04 1.236e-04\n",
            " 1.232e-04 1.228e-04 1.225e-04 1.222e-04 1.221e-04 1.218e-04 1.213e-04\n",
            " 1.209e-04 1.206e-04 1.201e-04 1.198e-04 1.195e-04 1.192e-04 1.187e-04\n",
            " 1.183e-04 1.181e-04 1.178e-04 1.174e-04 1.171e-04 1.170e-04 1.166e-04\n",
            " 1.162e-04 1.158e-04 1.154e-04 1.152e-04 1.149e-04 1.146e-04 1.143e-04\n",
            " 1.140e-04 1.139e-04 1.136e-04 1.130e-04 1.126e-04 1.123e-04 1.122e-04\n",
            " 1.121e-04 1.115e-04 1.111e-04 1.108e-04 1.107e-04 1.104e-04 1.102e-04\n",
            " 1.099e-04 1.098e-04 1.093e-04 1.089e-04 1.089e-04 1.087e-04 1.082e-04\n",
            " 1.077e-04 1.075e-04 1.074e-04 1.072e-04 1.067e-04 1.063e-04 1.062e-04\n",
            " 1.059e-04 1.056e-04 1.054e-04 1.052e-04 1.048e-04 1.043e-04 1.038e-04\n",
            " 1.037e-04 1.035e-04 1.030e-04 1.028e-04 1.026e-04 1.024e-04 1.020e-04\n",
            " 1.017e-04 1.017e-04 1.015e-04 1.012e-04 1.010e-04 1.008e-04 1.003e-04\n",
            " 9.979e-05 9.967e-05 9.939e-05 9.927e-05 9.897e-05 9.864e-05 9.824e-05\n",
            " 9.809e-05 9.779e-05 9.761e-05 9.716e-05 9.709e-05 9.675e-05 9.642e-05\n",
            " 9.619e-05 9.612e-05 9.579e-05 9.555e-05 9.550e-05 9.516e-05 9.486e-05\n",
            " 9.468e-05 9.423e-05 9.397e-05 9.368e-05 9.345e-05 9.310e-05 9.287e-05\n",
            " 9.240e-05 9.218e-05 9.202e-05 9.176e-05 9.167e-05 9.151e-05 9.092e-05\n",
            " 9.071e-05 9.035e-05 9.012e-05 9.001e-05 8.976e-05 8.967e-05 8.940e-05\n",
            " 8.926e-05 8.878e-05 8.862e-05 8.839e-05 8.817e-05 8.768e-05 8.737e-05\n",
            " 8.728e-05 8.717e-05 8.706e-05 8.679e-05 8.639e-05 8.617e-05 8.593e-05\n",
            " 8.561e-05 8.559e-05 8.552e-05 8.520e-05 8.503e-05 8.482e-05 8.457e-05\n",
            " 8.422e-05 8.404e-05 8.374e-05 8.353e-05 8.336e-05 8.329e-05 8.292e-05\n",
            " 8.286e-05 8.255e-05 8.244e-05 8.214e-05 8.192e-05 8.181e-05 8.176e-05\n",
            " 8.128e-05 8.121e-05 8.087e-05 8.043e-05 8.016e-05 7.998e-05 7.990e-05\n",
            " 7.975e-05 7.971e-05 7.926e-05 7.918e-05 7.910e-05 7.863e-05 7.844e-05\n",
            " 7.826e-05 7.790e-05 7.772e-05 7.747e-05 7.718e-05 7.706e-05 7.696e-05\n",
            " 7.673e-05 7.652e-05 7.639e-05 7.612e-05 7.567e-05 7.549e-05 7.523e-05\n",
            " 7.505e-05 7.484e-05 7.474e-05 7.439e-05 7.390e-05 7.367e-05 7.355e-05\n",
            " 7.353e-05 7.337e-05 7.310e-05 7.301e-05 7.292e-05 7.257e-05 7.234e-05\n",
            " 7.219e-05 7.203e-05 7.177e-05 7.164e-05 7.138e-05 7.111e-05 7.101e-05\n",
            " 7.081e-05 7.077e-05 7.049e-05 7.018e-05 7.007e-05 6.990e-05 6.971e-05\n",
            " 6.958e-05 6.943e-05 6.918e-05 6.885e-05 6.875e-05 6.856e-05 6.826e-05\n",
            " 6.806e-05 6.783e-05 6.771e-05 6.749e-05 6.723e-05 6.704e-05 6.683e-05\n",
            " 6.670e-05 6.654e-05 6.645e-05 6.627e-05 6.598e-05 6.577e-05 6.546e-05\n",
            " 6.524e-05 6.504e-05 6.482e-05 6.459e-05 6.433e-05 6.422e-05 6.393e-05\n",
            " 6.374e-05 6.363e-05 6.348e-05 6.334e-05 6.333e-05 6.306e-05 6.295e-05\n",
            " 6.275e-05 6.248e-05 6.226e-05 6.192e-05 6.174e-05 6.161e-05 6.151e-05\n",
            " 6.120e-05 6.098e-05 6.072e-05 6.036e-05 6.030e-05 6.022e-05 6.002e-05\n",
            " 5.998e-05 5.960e-05 5.943e-05 5.934e-05 5.923e-05 5.889e-05 5.877e-05\n",
            " 5.851e-05 5.815e-05 5.790e-05 5.780e-05 5.769e-05 5.745e-05 5.736e-05\n",
            " 5.709e-05 5.696e-05 5.682e-05 5.653e-05 5.623e-05 5.601e-05 5.586e-05\n",
            " 5.569e-05 5.567e-05 5.527e-05 5.511e-05 5.494e-05 5.464e-05 5.439e-05\n",
            " 5.434e-05 5.401e-05 5.380e-05 5.347e-05 5.338e-05 5.310e-05 5.283e-05\n",
            " 5.265e-05 5.238e-05 5.208e-05 5.170e-05 5.141e-05 5.138e-05]\n",
            "[[-6.164e-03  2.173e-03  3.991e-03 ...  6.395e-04 -1.740e-03  1.740e-03]\n",
            " [ 1.851e-03 -7.300e-04 -1.121e-03 ...  1.475e-04 -2.439e-04  2.439e-04]\n",
            " [-5.493e-04  5.411e-04  8.274e-06 ... -6.364e-06  7.604e-04 -7.604e-04]\n",
            " ...\n",
            " [-6.506e-03 -1.913e-03  8.419e-03 ...  2.827e-03 -1.415e-03  1.415e-03]\n",
            " [ 3.180e-04 -5.452e-03  5.134e-03 ... -1.285e-03  4.991e-04 -4.991e-04]\n",
            " [-1.010e-02 -1.073e-03  1.117e-02 ...  8.073e-03  2.719e-04 -2.719e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwBprdpUcYjp",
        "outputId": "30ee6833-9d4d-48b8-99f1-d8ce7bf08b82"
      },
      "source": [
        "#Try using several differnt models to see if any will lend support for the data under consideration\n",
        "\n",
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# load dataset\n",
        "X = selected_Features\n",
        "Y = train_labels\n",
        "\n",
        "\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('MNB', MultinomialNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "models.append(('ADA', AdaBoostClassifier()))\n",
        "models.append(('MLP', MLPClassifier()))\n",
        "\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "    cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "    \n",
        "    \n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: 0.349264 (0.027394)\n",
            "LDA: 0.315090 (0.036652)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN: 0.342990 (0.034205)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CART: 0.268779 (0.028570)\n",
            "NB: 0.243585 (0.034353)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNB: 0.267255 (0.024790)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM: 0.377707 (0.024598)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADA: 0.348242 (0.027576)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP: 0.335616 (0.022219)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8rbYBL1bcDv"
      },
      "source": [
        "#Multilayer perceptron \n",
        "#Multilayer perceptron \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=1000)\n",
        "\n",
        "# load dataset\n",
        "X = selected_Features\n",
        "Y = train_labels\n",
        "\n",
        "#with all data\n",
        "#X = train_features\n",
        "#Y = train_labels\n",
        "\n",
        "mlp.fit(selected_Features,train_labels)\n",
        "\n",
        "\n",
        "predict_train = mlp.predict(selected_Features)\n",
        "predict_test = mlp.predict(selected_Features_Test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ck0lDcjcJ5z"
      },
      "source": [
        "# The accuracy and the F1 score is around 0.61 and 0.59, respectively.Ideally, the perfect model will have the value of 1 for both these metrics, which is however, nearly impossible in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovas7udicFDf",
        "outputId": "6ed28f6d-f52a-488b-a26d-1d98ac8546b5"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(train_labels,predict_train))\n",
        "\n",
        "print(\"This Shows the performance of the model on the training data\")\n",
        "print(classification_report(train_labels,predict_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[459  11  27  14   6]\n",
            " [154  21  16  18  56]\n",
            " [ 87   6 211   6  63]\n",
            " [117   8  19 172  72]\n",
            " [ 68  15  91  20 164]]\n",
            "This Shows the performance of the model on the training data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AFR       0.52      0.89      0.65       517\n",
            "         AMR       0.34      0.08      0.13       265\n",
            "         EAS       0.58      0.57      0.57       373\n",
            "         EUR       0.75      0.44      0.56       388\n",
            "         SAS       0.45      0.46      0.46       358\n",
            "\n",
            "    accuracy                           0.54      1901\n",
            "   macro avg       0.53      0.49      0.47      1901\n",
            "weighted avg       0.54      0.54      0.51      1901\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es1xanutcBM0",
        "outputId": "50089a86-9580-4278-ae02-a2c5e9830e6e"
      },
      "source": [
        "print(confusion_matrix(test_labels,predict_test))\n",
        "print(classification_report(test_labels,predict_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[95  8 28 12  9]\n",
            " [48  2 17  2 18]\n",
            " [64  2 37 12 27]\n",
            " [41  4 21 26 25]\n",
            " [45  3 26 14 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AFR       0.32      0.62      0.43       152\n",
            "         AMR       0.11      0.02      0.04        87\n",
            "         EAS       0.29      0.26      0.27       142\n",
            "         EUR       0.39      0.22      0.28       117\n",
            "         SAS       0.38      0.35      0.37       136\n",
            "\n",
            "    accuracy                           0.33       634\n",
            "   macro avg       0.30      0.30      0.28       634\n",
            "weighted avg       0.31      0.33      0.30       634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnbnNfcIb8P7"
      },
      "source": [
        "###################################### Tune the model using GridSearchCV #################################\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(max_iter=1000)\n",
        "\n",
        "#Define a hyper-parameter space to search. (All the values that you want to try out\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhrajQhSut5K",
        "outputId": "b5fadc1c-0019-43f3-99d5-80b6ebc3b4f4"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#cv is the number of splits for cross validation Jobs defines the cpu resources to be used\n",
        "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
        "\n",
        "# load dataset\n",
        "X = selected_Features\n",
        "Y = train_labels\n",
        "\n",
        "clf.fit(selected_Features, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/rapids/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=1000), n_jobs=-1,\n",
              "             param_grid={'activation': ['tanh', 'relu'],\n",
              "                         'alpha': [0.0001, 0.05],\n",
              "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
              "                                                (100,)],\n",
              "                         'learning_rate': ['constant', 'adaptive'],\n",
              "                         'solver': ['sgd', 'adam']})"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Lcb-2eut5K"
      },
      "source": [
        "# NB This above step in the tuning process took a while to run."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehBQzET8ut5K"
      },
      "source": [
        "# Best parameters found:\n",
        "# {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "UdcXPmHlut5K",
        "outputId": "149f1243-8119-4cc6-cf1f-a1e2534b7a89"
      },
      "source": [
        "# Best parameter set\n",
        "print('Best parameters found:\\n', clf.best_params_)\n",
        "\n",
        "# All results\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            " {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.335 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.342 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.328 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.321 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.317 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.316 (+/-0.049) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.328 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.328 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.363 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.344 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.362 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.359 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.340 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.331 (+/-0.031) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.352 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.342 (+/-0.046) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.319 (+/-0.028) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.317 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.327 (+/-0.028) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.336 (+/-0.041) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.356 (+/-0.034) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.335 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.351 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.340 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.344 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.315 (+/-0.022) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.329 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.320 (+/-0.049) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.338 (+/-0.027) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.320 (+/-0.021) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.341 (+/-0.036) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.327 (+/-0.009) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.350 (+/-0.026) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.327 (+/-0.028) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.348 (+/-0.017) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.343 (+/-0.023) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.317 (+/-0.045) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.318 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.345 (+/-0.035) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.330 (+/-0.033) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.328 (+/-0.034) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.312 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.331 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.305 (+/-0.021) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.361 (+/-0.006) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
            "0.336 (+/-0.003) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
            "0.360 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
            "0.358 (+/-0.019) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJeWsYp7ut5L",
        "outputId": "7bd75e66-a05b-44ab-9529-aa1127a6466f"
      },
      "source": [
        "######################  Rerun the Neural network with the selected parameters #############################\n",
        "y_true, y_pred = test_labels , clf.predict(selected_Features_Test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AFR       0.33      0.43      0.37       152\n",
            "         AMR       0.20      0.17      0.19        87\n",
            "         EAS       0.35      0.35      0.35       142\n",
            "         EUR       0.36      0.32      0.34       117\n",
            "         SAS       0.37      0.31      0.34       136\n",
            "\n",
            "    accuracy                           0.33       634\n",
            "   macro avg       0.32      0.32      0.32       634\n",
            "weighted avg       0.33      0.33      0.33       634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQp8Gh0bbcDv"
      },
      "source": [
        "### SVM \n",
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='poly', degree=5)\n",
        "svclassifier.fit(train_features, train_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHyFAiKVut5L"
      },
      "source": [
        "#train_features, test_features, train_labels, test_labels\n",
        "y_pred1 = svclassifier.predict(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47OvbQ2iut5L",
        "outputId": "ac36857e-c658-47c6-bbf4-682ccda8c1f7"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "#print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(test_labels,y_pred1))\n",
        "print(classification_report(test_labels,y_pred1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[72 22 24 20 14]\n",
            " [28 21 12 15 11]\n",
            " [42 14 43 26 17]\n",
            " [31 11 15 48 12]\n",
            " [35 21 26 17 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AFR       0.35      0.47      0.40       152\n",
            "         AMR       0.24      0.24      0.24        87\n",
            "         EAS       0.36      0.30      0.33       142\n",
            "         EUR       0.38      0.41      0.40       117\n",
            "         SAS       0.41      0.27      0.33       136\n",
            "\n",
            "    accuracy                           0.35       634\n",
            "   macro avg       0.35      0.34      0.34       634\n",
            "weighted avg       0.35      0.35      0.34       634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ415brYbpJn"
      },
      "source": [
        "# References\n",
        "# 1.Machine Learning with Neural Networks Using scikit-learn https://www.pluralsight.com/guides/machine-learning-neural-networks-scikit-learn\n",
        "# 2. How to adjust the hyperparameters of MLP classifier to get more perfect performance https://datascience.stackexchange.com/questions/36049/how-to-adjust-the-hyperparameters-of-mlp-classifier-to-get-more-perfect-performa\n"
      ]
    }
  ]
}